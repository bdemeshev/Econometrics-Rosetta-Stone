## Python

Опять начинаем с импорта библиотек.
Почти всегда джентельменский набор включает *pandas*, *numpy* и *matplotlib.pyplot*. 
Много полезных функций для статистических расчетов можно найти в модуле Statsmodels. 


```{r}
source("../setup/setup_asya.R")
```


```{python}
import pandas as pd # работа с таблицами 
import numpy as np # математические функции и матрицы
import matplotlib.pyplot as plt # графики
import seaborn as sns # еще более классные графики

import statsmodels.api as sm # стандартные регресионные модели
import statsmodels.formula.api as smf # аналогичные модели с синтаксисом в стиле R
import statsmodels.graphics.gofplots as gf # визуализация моделей
import statsmodels.discrete.discrete_model # дискретные модели

from statsmodels.stats.outliers_influence import summary_table # работа с выбросами
from scipy.stats import shapiro # тест Шапиро – Уилка 
```

При желании можем настроить графики по своему вкусу, изменив [стиль](https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html) и другие параметры шрифтов и графиков :)

```{python}
plt.style.use('seaborn')
plt.rc('font', size=14)
plt.rc('figure', titlesize=15)
plt.rc('axes', labelsize=15)
plt.rc('axes', titlesize=15)
```

Загрузим данные.

```{python}
returns = pd.read_stata('../data/02_us_return.dta')
```

Переименуем столбцы с «неговорящими» названиями :)
Параметр `inplace=True` здесь (и во многих других функциях) позволяет изменить объект, не возвращая его копию.

```{python}
returns.rename(columns={'A':'n', 'B': 'date'}, inplace=True)
```

Избавимся от наблюдений с пропущенными значениями. 

```{python}
returns.dropna(inplace=True)
```

Как и прежде, рассмотрим CAPM модель :)
Оценим `бэту` для компании MOTOR. 
Тогда зависимая переменная - разница доходностей акций MOTOR и безрискового актива (`motor_premium`), а регрессор - рыночная премия (`market_premium`).

```{python}
returns['motor_premium'] = returns['MOTOR'] - returns['RKFREE']
returns['market_premium'] = returns['MARKET'] - returns['RKFREE'] 
```

Оценим модель и посмотрим на саммари :)

```{python}
regr = smf.ols('motor_premium ~ market_premium', data=returns).fit()
regr.summary()
```

Можем посчитать прогнозное значение. 

```{python}
returns['yhat'] = regr.fittedvalues
```

Красивые графики для остатков, выборосов и прочих радостей, как в R, придется строить ручками. Зато приятно поиграть с оформлением :)

```{python}
fig, ax = plt.subplots()
ax.plot(returns['market_premium'],regr.fittedvalues, color='g', alpha=0.8)
ax.scatter(returns['market_premium'],regr.fittedvalues + regr.resid, color='g', alpha=0.8, s=40)
ax.vlines(returns['market_premium'],regr.fittedvalues,regr.fittedvalues + regr.resid, color='gray', alpha=0.5)
plt.title('Линия регрессии и остатки')
plt.xlabel('RKFREE')
plt.ylabel('MARKET')
plt.show()
```

Строим $90\%$-й доверительный интервал.

```{python}
regr.conf_int(alpha = 0.1)
```

И проведем F-test.

```{python}
hypotheses = '(market_premium = 1)'
regr.f_test(r_matrix = hypotheses)
```

Тест Шапиро - Уилка. Такой же, как и в R. 

```{python}
W, p_value = shapiro(regr.resid)
```


Генерируем новые данные и строим предсказание.

```{python}
import random
random.seed(7)

new_data = np.random.normal(loc=0.01, scale=0.1)
prediction = regr.predict(new_data)
```

А теперь жесть! Построим графики, похожие на `plot()` R.

```{python}
fig_1 = plt.figure(1)

fig_1.axes[0] = sns.residplot(returns['market_premium'], returns['motor_premium'],
                                  lowess=True,
                                  scatter_kws={'alpha': 0.6},
                                  line_kws={'color': 'red', 'lw': 2, 'alpha': 0.8})

fig_1.axes[0].set_title('Residuals vs Fitted')
fig_1.axes[0].set_xlabel('Fitted values')
fig_1.axes[0].set_ylabel('Residuals')


# можем добавить метки потенциальных аутлаеров
abs_resid = abs(regr.resid).sort_values(ascending=False)
abs_resid_top3=abs_resid[:3]

for i in abs_resid_top3.index:
    fig_1.axes[0].annotate(i, 
                               xy = (regr.fittedvalues[i], 
                                   regr.resid[i]))
```


```{python}
norm_residuals = regr.get_influence().resid_studentized_internal # сохраним стьюдентизированные остатки 


QQ = gf.ProbPlot(norm_residuals)
fig_2 = QQ.qqplot(line='45', alpha=0.5, color='b', lw=1)


fig_2.axes[0].set_title('Normal Q-Q')
fig_2.axes[0].set_xlabel('Theoretical Quantiles')
fig_2.axes[0].set_ylabel('Standardized Residuals');

#и снова метки
abs_norm_resid = np.flip(np.argsort(abs(norm_residuals)), 0)
abs_norm_resid_top3 = abs_norm_resid[:3]

for r, i in enumerate(abs_norm_resid_top3):
    fig_2.axes[0].annotate(i, 
                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],
                                   norm_residuals[i]))
```


```{python}
fig_3 = plt.figure(3)

plt.scatter(regr.fittedvalues, np.sqrt(abs(norm_residuals)), alpha=0.5)
sns.regplot(regr.fittedvalues, np.sqrt(abs(norm_residuals)), 
            scatter=False, 
            ci=False, 
            lowess=True,
            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.6})

fig_3.axes[0].set_title('Scale-Location')
fig_3.axes[0].set_xlabel('Fitted values')
fig_3.axes[0].set_ylabel('$\sqrt{|Standardized Residuals|}$')

# и еще раз!)
abs_sq_norm_resid = np.flip(np.argsort(np.sqrt(abs(norm_residuals)), 0))
abs_sq_norm_resid_top3 = abs_sq_norm_resid[:3]

for i in abs_sq_norm_resid_top3:
    fig_3.axes[0].annotate(i, xy=(regr.fittedvalues[i], 
                                   np.sqrt(abs(norm_residuals)[i])))
```

```{python, MESSAGE=FALSE}
leverage = regr.get_influence().hat_matrix_diag # сохраняем элементы матрицы-шляпницы
cook_dist = regr.get_influence().cooks_distance[0] # и расстояние Кука

fig_4 = plt.figure(4)

plt.scatter(leverage, norm_residuals, alpha=0.5)
sns.regplot(leverage, norm_residuals, 
            scatter=False, 
            ci=False, 
            lowess=True,
            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})

fig_4.axes[0].set_xlim(0, 0.20)  # РАЗВЕСТИ НА ОТДЕЛЬНЫЕ ЧАНКИ ИЛИ MESSAGE = FALSE
fig_4.axes[0].set_ylim(-3, 5)
fig_4.axes[0].set_title('Residuals vs Leverage')
fig_4.axes[0].set_xlabel('Leverage')
fig_4.axes[0].set_ylabel('Standardized Residuals')


leverage_top3 = np.flip(np.argsort(cook_dist), 0)[:3]

for i in leverage_top3:
    fig_4.axes[0].annotate(i, 
                               xy=(leverage[i], 
                                   norm_residuals[i]))
plt.show()
```
