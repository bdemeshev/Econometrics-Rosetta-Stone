## R

Загрузим необходимые пакеты.

```{r "packages", results='hide', message=FALSE, warning=FALSE}
library(tidyverse) # манипуляции с данными и построение графиков
library(sjPlot) # визуализация моделей
library(skimr) # симпатичное summary
library(rio) # чтение .dta файлов
library(MASS) # отрицательное биномиальное распределение
library(lmtest) # проверка гипотез
library(pscl) # zero-inflation function
library(margins) # подсчет предельных эффектов
```


Импортируем данные.
```{r "import data"}
df_fish = rio::import(file = "../data/05_fish.dta")
```
Данные содержат информацию о количестве рыбы, пойманной людьми на отдыхе. 

Camper - наличие/отсутствие палатки.
Child - количество детей, которых взяли на рыбалку.
Persons - количество людей в группе.
Count - количество пойманной рыбы


Посмотрим нам описательные статистики. 

```{r "skim"}
skim(fish)
```

Переменная `camper` принимает всего два значения, поэтому превратим ее в факторную переменную.

```{r "factor"}
fish = mutate(fish, camper = factor(camper))
```

Наша задача - по имеющимся данным предсказать улов. 
Для начала посмотрим на распределение объясняемой переменной `count`.

```{r "hist"}
ggplot(fish, aes(x = count)) + 
  geom_histogram(binwidth = 1) + 
  labs(x = 'count', y = 'frequency', title = 'Distribution of count variable')
```

Предположим, что переменная имеет распределение Пуассона. Будем использовать пуассоновскую регрессию. 
\[
P(y=k)=exp(-\lambda) \lambda^k / k!
\]
где $\lambda=\exp(b_1 +b_2*x)$

```{r "poisson"}
poisson_model = glm(count ~ child + camper +  persons, family = "poisson", data = fish)
summary(poisson_model)
```

Посчитаем средний предельный эффект для каждой переменной.

```{r "mef", message=FALSE, warning=FALSE}
m = margins(poisson_model)
summary(m)
cplot(poisson_model, x = 'persons', what = 'effect', title = 'Предельный эффект переменной camper')
margins(poisson_model, at = list(child = 0:1)) 
plot_model(poisson_model, type = 'pred')
plot_model(poisson_model, type = "pred", terms = c("child [0, 0, 1]", "persons [1,3]"))
```

Однако, заметим, что дисперсия и среднее значение объясняемой переменной не равны, как это предполагает распределение Пуассона.

```{r "with"}
fish %>% 
  group_by(camper) %>% 
  summarize(var = var(count), mean = mean(count))
```

Оценим регрессию, предполагая отрицательное биномиальное распределение остатков. 
В этом случае дисперсия распределения зависит от некоторого параметра и не равна среднему.

```{r "nb"}
nb1 = glm.nb(count ~ child + camper +  persons, data = fish)
summary(nb1)
```

Попробуем исключить из модели переменную `camper` и сравним качество двух моделей.

```{r "excl"}
nb2 = update(nb1, . ~ . - camper)
waldtest(nb1, nb2)
```


Можем посмотреть на результаты модели с "раздутыми нулями" (zero-inflated).
Они предполагают большую частоту нулевых наблюдений.

```{r "zero_infl"}
zero_infl = zeroinfl(count ~  child + camper | persons, data = fish, dist = 'negbin')
summary(zero_infl)

plot_model(zero_infl, type = 'pred')
```