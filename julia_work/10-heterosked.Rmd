# Гетероскедастичность в простой регрессии {#heterosked}
```{r stata_py_setup, include=FALSE}
library(knitr) # комбинирование кода и текста
library(Statamarkdown) # взаимодействие со статой
library(reticulate) # взаимодействие с питоном
if (Sys.getenv("USER") == "boris") {
  stataexe <- find_stata()
}
if (Sys.getenv("USERNAME") == "Yuliya") {
  use_python("/Users/Юлия/AppData/Local/Programs/Python/Python37/python.exe")
  stataexe <- find_stata()
}
if (Sys.getenv("USER") == "Sasha") {
  use_python("/Users/Sasha/anaconda3/bin/python3")
  stataexe = "/Applications/Stata/StataSE.app/Contents/MacOS/stataSE"
}
if (Sys.getenv("USERNAME") == "Anastasia Karpova") {
  Sys.setenv(language = "russian")
  Sys.setenv(PATH = paste("C:/Users/DNS/Anaconda3/Library/bin",
                       Sys.getenv()["PATH"], sep = ";"))
  Sys.setenv(PATH = paste("C:/Users/DNS/Anaconda3/Scripts",
                       Sys.getenv()["PATH"], sep = ";"))
  Sys.setenv(PATH = paste("C:/Users/DNS/Anaconda3/",
                       Sys.getenv()["PATH"], sep = ";"))
  use_condaenv("base")
  use_python("C:/Users/DNS/Anaconda3/python.exe")
  pandas = reticulate::import("pandas")
  stataexe = "C:/Program Files (x86)/Stata13/StataMP-64.exe"
}
if (Sys.getenv("USERNAME") == "The_sun") {
  use_python("Users/The_sun/Anaconda3/python.exe")
  stataexe = "C:/Program Files (x86)/Stata13/StataMP-64.exe"
}
knitr::opts_chunk$set(engine.path = list(stata = stataexe), collectcode = TRUE)
```

```{r setup, include=FALSE}
library(texreg)
library(Statamarkdown)
library(reticulate)
library (knitr)
library(dplyr)
library(rmarkdown)
stataexe <- find_stata()
knitr::opts_chunk$set(engine.path = list(stata = stataexe), collectcode = TRUE)
opts_chunk$set(fig.align = "center") # выравнивание картинок по центру
```

> Одним из нарушений условий ТГМ является гетероскедастичность, возникающая ввиду неодинаковых дисперсий для разных наблюдений. 
Она нежелательна ввиду того, что оценки МНК не являются эффективными (но остаются несмещёнными), и предпосылки для использования `t`-статистик нарушены, что даёт неверный результат о значимости коэффициентов.

Этот коан благословит Вас на поиски гетероскедастичности и просветит о способах борьбы с ней.

Будем анализировать гетероскедастичность на данных о стоимости квартир.

## R

Вызовем **r** в помощь в охоте на гетероскедастичность. Импортируем его оружейные пакеты.

```{r, message=FALSE, warning=FALSE}
library(rio) # импорт и экспорт данных в разных форматах
library(dplyr) # манипуляции с данными
library(lmtest) # тест Бройша-Пагана
library(sandwich) # оценка дисперсии при гетероскедастичности
library(UStatBookABSC) # WLS
library (estimatr) # получение робастных оценок
library(ggpubr) # для графиков
library(skimr) # для описательных статистик
```

Импортируем наш dataset, `flats.dta`:

```{r}
flats= import("data/flats.dta")
```

Рассмотрим описательные статистики загруженного датасета.

```{r}
skim(flats)
```

Построим простую линейную регрессионную модель, на которой будем проверять гетероскедастичность.

```{r}
reg = lm(ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist, data = flats)
summary(reg)
```

Проверим наличие гетероскедастичности визуально. Построим зависимости цены квартир от объясняющих факторов.

```{r}
kit = ggplot(flats) + geom_point(aes(x = ln_kitsp, y = ln_price_metr)) + 
  labs(x = "Площадь кухни, кв.м", y = "Цена квартиры, $1000", 
  title = "Стоимость квартир в Москве")
live = ggplot(flats) + geom_point(aes(x = ln_livesp, y = ln_price_metr)) + 
  labs(x = "Жилая площадь, кв.м", y = "Цена квартиры, $1000", 
  title = "Стоимость квартир в Москве")
dist = ggplot(flats) + geom_point(aes(x = ln_dist, y = ln_price_metr)) + 
  labs(x = "Расстояние до центра, м", y = "Цена квартиры, $1000",
  title = "Стоимость квартир в Москве")
metrdist = ggplot(flats) + geom_point(aes(x = ln_metrdist, y = ln_price_metr)) + 
  labs(x = "Расстояние до метро, м", y = "Цена квартиры, $1000", 
  title = "Стоимость квартир в Москве")

ggarrange(kit, live, dist, metrdist, ncol = 2, nrow = 2)
```

Из сета красивых графиков видно, что гетероскедастичность присутствует. В частности, подозрительны переменные `ln_kitsp` и `ln_metrdist`.

Проверим наличие гетероскедастичности с помощью тестов. 

Начнём с теста Уайта. Он неконструктивный, он может лишь показать наличие гетероскедастичности, асимптотический. Нормальность остатков в предпосылках не требуется, подразумевается, что $$E({\varepsilon^4_i}) = const$$.

\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \neq = \sigma^2 \\
\end{cases}
\]

На первом шаге тест сохраняет остатки от построения начальной регрессии.
\[
\hat{\ln{(pricemetr_i)}} = \hat{\beta}_0 + \hat{\beta}_{\ln{(kitsp)}} \cdot \ln{(kitsp_i)} + \hat{\beta}_{\ln{(livesp)}}\cdot \ln{(livesp_i)} + \hat{\beta}_{\ln{(dist)}}\cdot \ln{(dist_i)} + \hat{\beta}_{\ln{(metrdist)}}\cdot \ln{(metrdist_i)}
\]
На втором - строится вспомогательная регрессия (X_j-вектор j-го фактора).
\[
\hat{e}^2_i = \hat{\alpha}_0 + \sum_{j=1}^{k} \hat{\alpha}_j \cdot X_j + \sum_{j=1}^{k} \hat{\gamma}_j \cdot X^2_j + \sum_{j < m}^{k} \hat{\delta}_j X_j \cdot X_m
\]

`R-squared` построенной вспомогательной регрессии должен быть распределён как:
\[
n \cdot R^2_{aux} \sim \chi^2_{K-1}
\]
где `K` – число факторов во вспомогательной регрессии.

Тест Уайта реализуется в **r** (ручками) как:
```{r}
bptest(reg, varformula = ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist + I(ln_livesp ^ 2) + I(ln_kitsp ^ 2) + I(ln_dist ^ 2) + I(ln_metrdist ^ 2) + I(ln_livesp * ln_kitsp) + I(ln_livesp * ln_dist) + I(ln_livesp * ln_metrdist) + I(ln_kitsp * ln_dist) + I(ln_kitsp * ln_metrdist) + I(ln_dist * ln_metrdist), data = flats)
```

Тест Уайта выявил гетероскедастичность.

Тест Бройша - Пагана — обобщённый вариант теста Уайта. 
В тесте Бройша-Пагана во вспомогательной регрессии можно брать любые функции от регрессоров, в тесте Уайта - регрессоры, их квадраты и кросс-произведения. 
Тест Бройша-Пагана является асимптотическим.

\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \propto f(\alpha_0 + \alpha_1 \cdot Z_1 +  \ldots + \alpha_p \cdot Z_p) \\
\end{cases}
\]

Классическая версия Бройша - Пагана строится на основе метода максимального правдоподобия. Предпосылками классической версии теста являются нормальность остатков, существование у функции дисперсии из альтернативной гипотезы первой и второй производной. 
Считается LM-статистика, которая, при верной основной гипотезе об отсутствии гетероскедастичности, имеет хи-квадратное распределение с p-1 степенью свободы.

Классическая версия Бройша - Пагана реализуется в **r** по команде:

```{r}
bptest(reg, studentize = FALSE)
```

Современная модификация теста не требует нормальности остатков, лишь $${\mathbb E}({\varepsilon^4_i}) = const$$.

На первом шаге строится исходная регрессия и сохраняются остатки. 
Затем строится состоятельная оценка дисперсии:
\[
\hat{\sigma}^2 = \frac{1}{n} \cdot \sum_{i=1}^{n} {e^2_i}
\]

Потом строится вспомогательная регрессия:

\[
\frac{e^2}{\hat{\sigma}^2} = \alpha_0 + \alpha_1 \cdot Z_1 + \ldots + \alpha_p \cdot Z_p + u
\]

И рассчитывается тестовая статистика:

\[
\frac{RSS_{aux}}{2} \sim \chi^2_{p}
\]

Модифицированная версия теста Бройша - Пагана реализуется по команде:

```{r}
bptest(reg)
```

Причем, если отдельно не указать спецификацию вспомогательной регрессии, то `bptest()` возьмёт все регрессоры исходной модели.

В обеих версиях теста Бройша - Пагана гетероскедастичность обнаружена.

Ещё есть тест Голдфелда - Квандта. 


\[
\begin{cases}
H_0: \sigma^2_i = \sigma^2 \\
H_1: \sigma^2_i \propto X_i \\
\end{cases}
\]

Этот тест предполагает нормальность остатков и является неасимптотическим.

Процедура:

Сначала все наблюдения сортируются по возрастанию абсолютного значения фактора, вызывающего гетероскедастичность.

Затем отсортированный ряд по фактору делится на 3 примерно равные части. Считаются гетероскедастичности по первой и третьей части ряда. 
Строится `F`- статистика:
\[
\frac{RSS_2}{RSS_1} \sim F_{r - k, r-k}
\]

где `r` - размер первой и третьей частей отсортированного ряда.

Данный тест в **r** реализуется по командам (предполагается, что дисперсии пропорциональны переменной `ln_kitsp`):

```{r}
flats_ordered = flats[order(flats$ln_kitsp), ]
reg_gqtest = lm(ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist, data = flats_ordered)
gqtest(reg_gqtest, fraction = 0.34) # посередине отсортированного ряда лежит 34% наблюдений
```

Будет также полезным познакомиться с методами борьбы с гетероскедастичностью.

Способ 1. Взвешенный МНК. Веса – оценка обратной дисперсии переменной, вызывающей гетероскедачность.

То есть оценим регрессию:
\[
\frac{\ln{(pricemetr_i)}}{\hat{\sigma}_i} = 
\frac{\beta_0}{\hat{\sigma}_i} + 
\frac{\beta_{\ln{(kitsp)}} \cdot \ln{(kitsp_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(livesp)}} \cdot \ln{(livesp_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(dist)}} \cdot \ln{(dist_i)}}{\hat{\sigma}_i} + \frac{\beta_{\ln{(metrdist)}} \cdot \ln{(metrdist_i)}}{\hat{\sigma}_i} + \frac{\varepsilon_i}{\hat{\sigma}_i}
\]

В **r** это можно сделать так:

```{r}
reg_wls = lm(ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist, data = flats, weights = 1 / (1 / fitted(lm(abs(residuals(reg)) ~ ln_kitsp)) ^ 2))
summary(reg_wls)
```

Способ 2. Робастные оценки Уайта.

```{r}
coeftest(reg, vcov = vcovHC(reg, "HC0"))
```

Робастные оценки коэффициентов регрессии получаются состоятельными. 

## python

Теперь попробуем проделать эти шаги в **python**.

```{r, include=FALSE}
library(reticulate)
use_python("/users/yuliya/appdata/local/programs/python/python37-32")
```

Импотируем необходимые пакеты.

```{python}
import numpy as np
import pandas as pd # чтение файлов
import matplotlib.pyplot as plt # построение графиков
import seaborn as sns # построение графиков
import statsmodels.api as sm # тесты
from statsmodels.formula.api import ols, WLS # построение регрессии
import statsmodels
import statsmodels.stats.diagnostic as sm_diagnostic # тест Бройша-Пагана
```

Загрузим исследуемый датасет.

```{python}
flats = pd.read_stata("data/flats.dta")
```

Построим линейную регрессионную модель.

```{python, warning=FALSE}
reg = ols("ln_price_metr ~ 1 + ln_livesp + ln_kitsp + ln_dist + ln_metrdist", flats).fit()
reg.summary()
```

Визуализируем зависимости регрессоров и регрессанта.

```{python}
sns.pairplot(flats, x_vars=["ln_metrdist", "ln_kitsp", "ln_livesp", "ln_dist"], y_vars=["ln_price_metr"])
plt.show()
```

Графики всё такие же красивые, как и в предыдущем пункте:) 
Подозрительны переменные `ln_kitsp` и `ln_metrdist`.
Проведём тесты на выявление гетероскедастичности в **python**.

Рассмотрим тест Бройша - Пагана на всех факторах.

```{python}
resid = reg.resid
X = flats[["ln_livesp", "ln_kitsp", "ln_dist", "ln_metrdist"]]
sm_diagnostic.het_breuschpagan(resid=resid, exog_het=X)
```

Интерпретация результатов теста: 
Первое из выданных значений - значение тестовой статистики теста Бройша - Пагана, второе - значение p-value для выданной тестовой статистики. 
Третье  и четвёртое - значения тестовой статистики и её p-value для на уровне значимости 5% (табличное). 
Гетероскедастичность присутствует.

Посмотрим на тест Голдфелда - Квандта по переменной `ln_kitsp`.

```{python}
sm_diagnostic.het_goldfeldquandt(y=flats["ln_price_metr"], x=X, alternative="two-sided")
```

Значение p-value близко к 0, следовательно, основная гипотеза о гомоскедастичности отвергается.

Теперь о способах борьбы с гетероскедастичностью.

Способ 1. Взвешенный МНК.

Взвешиваем по стандартному отклонению фактора `ln_kitsp`.

```{python}
reg_wls = statsmodels.regression.linear_model.WLS(flats["ln_price_metr"], X, weights=flats["ln_kitsp"])
reg_wls_results = reg_wls.fit()
reg_wls_results.summary()
```

Способ 2. Использование робастных оценок.

```{python}
reg_robust = reg.get_robustcov_results()
reg_robust.summary()
```

## Stata

Теперь попробуем поработать в **stata**.

Импортируем датасет для анализа.

```{stata}
use data/flats.dta
```

Построим линейную регрессионную модель.

```{stata}
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist
```

Визуализируем зависимость регрессоров и регрессанта.

```{stata,echo=1,results="hide"}
scatter ln_price_metr ln_kitsp
graph export kitsp.png, replace
```
<center>
![](kitsp.png)
</center>

```{stata,echo=1,results="hide"}
scatter ln_price_metr ln_livesp
graph export livesp.png, replace
```

<center>

![](livesp.png)

</center>

```{stata,echo=1,results="hide"}
scatter ln_price_metr ln_dist
graph export dist.png, replace
```

<center>

![](dist.png)

</center>

```{stata,echo=1,results="hide"}
scatter ln_price_metr ln_metrdist
graph export metrdist.png, replace
```

<center>

![](metrdist.png)

</center>


Подозрительны переменные `ln_kitsp` и `ln_metrdist`.
Проверим наличие гетероскедастичности с помощью тестов.

Тест Уайта строится по короткой команде:

```{stata}
estat imtest, white
```

Тест Уайта выявил гетероскедастичность. Что скажет тест Бройша - Пагана?

```{stata}
estat hettest, rhs mtest
```

И этот тест указывает на наличие нежелательной гетероскедастичности, особенно подозрительны переменные `ln_kitsp` и `ln_metrdist`.

Попробуем проверить ещё и через тест Голдфелда - Квандта. Сделаем его ручками.

Отсортируем наблюдения по возрастанию переменной `ln_kitsp`, построим регрессию и сохраним остатки.

```{stata}
sort ln_kitsp
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist in 1 / 258
scalar rss1 = e(rss)
```

Сохраним остатки и в последней части регрессии.

```{stata}
sort ln_kitsp
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist in 516 / 773
scalar rss2 = e(rss)
```

Посчитаем тестовую F-статистику.

```{stata}
scalar F = rss2 / rss1
display F
display invFtail(258, 258, 0.05)
```

Тестовая статистика больше табличной, следовательно, гетероскедастичность присутствует. 

Сейчас немного о способах борьбы с гетероскедастичностью. 
Подправим все коэффициенты исходной регрессии на гетероскедастичную переменную, например, на `ln_kitsp`.

```{stata}
gen ln_price_metr_new = ln_price_metr / ln_kitsp
gen ln_livesp_new = ln_livesp / ln_kitsp
gen const_new = 1 / ln_kitsp
gen ln_dist_new = ln_dist / ln_kitsp
gen ln_metrdist_new = ln_metrdist / ln_kitsp
```

И оценим регрессию с новыми переменными.

```{stata}
reg ln_price_metr_new ln_livesp_new const_new ln_dist_new ln_metrdist_new
```

И полученные оценки будут эффективными оценками коэффициентов исходной регрессии.

Также можно использовать метод взвешенного МНК (WLS). Взвесим на стандартное отклонение фактора `ln_kitsp`.

```{stata}
vwls ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist, sd(ln_kitsp)
```

Способ #2. Используем робастные оценки Уайта.

```{stata}
reg ln_price_metr ln_livesp ln_kitsp ln_dist ln_metrdist, robust
```

Робастные оценки Уайта позволяют снизить последствия гетероскедастичности через уменьшение стандартных ошибок коэффициентов регрессии.

```{stata, include=FALSE}
save data/livesp.dta, replace
```








